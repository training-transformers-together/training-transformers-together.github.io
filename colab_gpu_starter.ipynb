{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab_gpu_starter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivCbovmkZ6dA"
      },
      "source": [
        "### Colab starter kit\n",
        "_This notebook is a part of [Training-Transformers-Together](training-transformers-together.github.io/) NeurIPS demonstration._\n",
        "\n",
        "To participate in the demo training run, you need to follow these steps:\n",
        "1. Log in on [huggingface.co](https://huggingface.co)\n",
        "   * If you don't have an account or if you want to participate anonymously, you can create a new account at [huggingface.co/join](https://huggingface.co/join),\n",
        "2. Join our organization using this [__invite link__](https://huggingface.co/organizations/training-transformers-together/share/otdYDceuoEIGEVXhrmYilPSnVUrnsrjJNz)\n",
        "3. Create a new User Access token at [huggingface.co/settings/token](https://huggingface.co/settings/token) and copy it to the clipboard\n",
        "4. Run the code below: it will ask you for your token, then setup and begin training. That's it!\n",
        "\n",
        "If everything is fine, you will soon see your contribution on the [__training dashboard__](https://huggingface.co/spaces/training-transformers-together/Dashboard).\n",
        "\n",
        "If you have any questions, technical difficulties or just want to chat about distributed training, you can find us here: [![Discord](https://img.shields.io/static/v1?style=default&label=Discord&logo=discord&message=join)](https://discord.gg/uGugx9zYvN)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Em9rd8rysw",
        "outputId": "40ef63d0-ee3c-4021-e293-9fb1b4cbb1bc"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "os.environ['HF_USER_ACCESS_TOKEN'] = getpass(\"Please enter your HF token here:\")\n",
        "\n",
        "!pip install -q https://github.com/learning-at-home/hivemind/archive/dalle-v1.zip &> log\n",
        "!git clone https://github.com/learning-at-home/dalle-hivemind &> log\n",
        "!cd dalle-hivemind && pip install -q -r requirements.txt &> log\n",
        "print(\"done!\")\n",
        "\n",
        "exp_name = \"dalle-v1\"\n",
        "%env HF_ORGANIZATION_NAME=training-transformers-together\n",
        "%env HF_MODEL_NAME={exp_name}\n",
        "%env WANDB_API_KEY=bfcfdc646d9481c372938d5370b4f902f7d7f420\n",
        "%env WANDB_ENTITY=learning-at-home\n",
        "%env WANDB_PROJECT=dalle-hivemind-trainers\n",
        "\n",
        "\n",
        "!ulimit -n 16384 && cd dalle-hivemind && python run_trainer.py --experiment_prefix {exp_name} --client_mode True \\\n",
        " --initial_peers /ip4/52.232.13.142/tcp/31234/p2p/QmWMNBvt3VkVETzQ68Uk44PokVjwA8sSvEEB3z8WwA5ZAS /ip4/193.106.95.184/tcp/31234/p2p/QmegUJSucRpaUrozQoP8B5ocAXhdnxQDrTdoUu5trtCoWc /ip4/52.232.13.143/tcp/31234/p2p/Qme6k7Ey6qz1sqi3QVzwXbop4UA33NP2sv6BStJqnvbRef \\\n",
        " --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --matchmaking_time 20 --allreduce_timeout 120\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please paste your HF token here:路路路路路路路路路路\n",
            "Cloning into 'dalle-hivemind'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 165 (delta 97), reused 106 (delta 45), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (165/165), 52.19 KiB | 5.22 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n",
            "Collecting git+git://github.com/learning-at-home/hivemind@dalle-v1 (from -r requirements.txt (line 1))\n",
            "  Cloning git://github.com/learning-at-home/hivemind (to revision dalle-v1) to /tmp/pip-req-build-ui4172ki\n",
            "  Running command git clone -q git://github.com/learning-at-home/hivemind /tmp/pip-req-build-ui4172ki\n",
            "  Running command git checkout -b dalle-v1 --track origin/dalle-v1\n",
            "  Switched to a new branch 'dalle-v1'\n",
            "  Branch 'dalle-v1' set up to track remote branch 'dalle-v1' from 'origin'.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+git://github.com/learning-at-home/dalle-pytorch@weight-sharing (from -r requirements.txt (line 2))\n",
            "  Cloning git://github.com/learning-at-home/dalle-pytorch (to revision weight-sharing) to /tmp/pip-req-build-r8ixqd0p\n",
            "  Running command git clone -q git://github.com/learning-at-home/dalle-pytorch /tmp/pip-req-build-r8ixqd0p\n",
            "  Running command git checkout -b weight-sharing --track origin/weight-sharing\n",
            "  Switched to a new branch 'weight-sharing'\n",
            "  Branch 'weight-sharing' set up to track remote branch 'weight-sharing' from 'origin'.\n",
            "Collecting bitsandbytes-cuda111>=0.26.0\n",
            "  Downloading bitsandbytes_cuda111-0.26.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     || 4.0 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.9.2\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     || 3.1 MB 33.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.2\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     || 3.3 MB 37.4 MB/s \n",
            "\u001b[?25hCollecting datasets>=1.11.0\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     || 298 kB 42.2 MB/s \n",
            "\u001b[?25hCollecting torch_optimizer>=0.1.0\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     || 61 kB 454 kB/s \n",
            "\u001b[?25hCollecting wandb>=0.10.33\n",
            "  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     || 1.7 MB 35.8 MB/s \n",
            "\u001b[?25hCollecting nltk>=3.6.2\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     || 1.5 MB 29.4 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     || 1.2 MB 23.3 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     || 1.1 MB 26.4 MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     || 62 kB 800 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (1.1.0)\n",
            "Collecting axial_positional_embedding\n",
            "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
            "Collecting DALL-E\n",
            "  Downloading DALL_E-0.1-py3-none-any.whl (6.0 kB)\n",
            "Collecting einops>=0.3.2\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     || 64 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting g-mlp-pytorch\n",
            "  Downloading g_mlp_pytorch-0.1.5-py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (2019.12.20)\n",
            "Collecting rotary-embedding-torch\n",
            "  Downloading rotary_embedding_torch-0.1.2-py3-none-any.whl (4.1 kB)\n",
            "Collecting taming-transformers-rom1504\n",
            "  Downloading taming_transformers_rom1504-0.0.6-py3-none-any.whl (51 kB)\n",
            "\u001b[K     || 51 kB 240 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (4.62.3)\n",
            "Collecting youtokentome\n",
            "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "\u001b[K     || 1.7 MB 24.3 MB/s \n",
            "\u001b[?25hCollecting WebDataset\n",
            "  Downloading webdataset-0.1.103-py3-none-any.whl (47 kB)\n",
            "\u001b[K     || 47 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio-tools>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.42.0)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (36.0.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.0.3)\n",
            "Requirement already satisfied: uvloop>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: pymultihash>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: prefetch-generator>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.42.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: configargparse>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (3.17.3)\n",
            "Requirement already satisfied: multiaddr>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (0.0.9)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (2.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     || 61 kB 486 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.9.2->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.9.2->-r requirements.txt (line 4)) (4.8.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     || 895 kB 24.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.9.2->-r requirements.txt (line 4)) (21.3)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     || 596 kB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.11.0->-r requirements.txt (line 6)) (0.70.12.2)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     || 132 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.11.0->-r requirements.txt (line 6)) (1.1.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     || 243 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.11.0->-r requirements.txt (line 6)) (0.3.4)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.11.0->-r requirements.txt (line 6)) (3.0.0)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.33->-r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.33->-r requirements.txt (line 8)) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.33->-r requirements.txt (line 8)) (1.15.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     || 97 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.33->-r requirements.txt (line 8)) (5.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.33->-r requirements.txt (line 8)) (2.8.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     || 140 kB 49.2 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     || 180 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     || 749 kB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.2->-r requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->-r requirements.txt (line 12)) (2.0.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->-r requirements.txt (line 12)) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.4.6->hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.4.6->hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (2.21)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     || 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb>=0.10.33->-r requirements.txt (line 8)) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: varint in /usr/local/lib/python3.7/dist-packages (from multiaddr>=0.0.9->hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from multiaddr>=0.0.9->hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: netaddr in /usr/local/lib/python3.7/dist-packages (from multiaddr>=0.0.9->hivemind==1.0.0.dev0->-r requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.9.2->-r requirements.txt (line 4)) (3.0.6)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     || 192 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     || 271 kB 50.1 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     || 160 kB 46.1 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 11)) (21.2.0)\n",
            "Collecting mypy\n",
            "  Downloading mypy-0.910-cp37-cp37m-manylinux2010_x86_64.whl (21.5 MB)\n",
            "\u001b[K     || 21.5 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting blobfile\n",
            "  Downloading blobfile-1.2.7-py3-none-any.whl (65 kB)\n",
            "\u001b[K     || 65 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from DALL-E->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (3.6.4)\n",
            "Collecting xmltodict~=0.12.0\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting pycryptodomex~=3.8\n",
            "  Downloading pycryptodomex-3.12.0-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     || 2.0 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     || 138 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.9.2->-r requirements.txt (line 4)) (3.6.0)\n",
            "Collecting typed-ast<1.5.0,>=1.4.0\n",
            "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     || 743 kB 38.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from mypy->DALL-E->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.10.2)\n",
            "Collecting mypy-extensions<0.5.0,>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.11.0->-r requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (8.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (1.4.0)\n",
            "Collecting pytorch-lightning>=1.0.8\n",
            "  Downloading pytorch_lightning-1.5.5-py3-none-any.whl (525 kB)\n",
            "\u001b[K     || 525 kB 47.1 MB/s \n",
            "\u001b[?25hCollecting omegaconf>=2.0.0\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     || 74 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     || 112 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     || 829 kB 40.8 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.6.1-py3-none-any.whl (332 kB)\n",
            "\u001b[K     || 332 kB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle-pytorch==1.1.2->-r requirements.txt (line 2)) (3.1.1)\n",
            "Collecting braceexpand\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Building wheels for collected packages: dalle-pytorch, subprocess32, axial-positional-embedding, ftfy, pathtools, antlr4-python3-runtime, future\n",
            "  Building wheel for dalle-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dalle-pytorch: filename=dalle_pytorch-1.1.2-py3-none-any.whl size=1385577 sha256=f6f55453ec8a2a0477afd7f967422b43b185c6f76b048a1521ac58f1e51f7d8d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-821__pl5/wheels/6f/0f/9d/60f5e0b6f52942004f5eb4d760a4eebaa112e33fecc3a11d0c\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=0b46b364952dd379d08168c4f61a15b6d91279b45d71e2c228513e7209199c8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2900 sha256=48b20deb656df88ea425f364358535a7ca174e99ade4e5d2f72fe7d244a25da1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/2c/c3/9a1cb267c0d0d9b6eeba7952addb32b17857d1f799690c27a8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=de1c7e23f3690d72c1d5f8d4b1601c4baec004db21c2d28d48fccd8f62ff9cbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=50d0fcdd9f0ed981ba9a676f6a985f29ef67f255858364eca9efc7525d370233\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=4bfa5c4f5e221ebb31b1144bff8af351c42a4f7159ff5208452d3e53f599468c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=70e3c01154a101570a06fa53e6cd98b91461a294c871f8e1ac6667081390f42b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built dalle-pytorch subprocess32 axial-positional-embedding ftfy pathtools antlr4-python3-runtime future\n",
            "Installing collected packages: urllib3, requests, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xmltodict, typed-ast, torchmetrics, smmap, regex, PyYAML, pyDeprecate, pycryptodomex, mypy-extensions, future, antlr4-python3-runtime, tokenizers, sacremoses, pytorch-lightning, omegaconf, mypy, huggingface-hub, gitdb, einops, braceexpand, blobfile, youtokentome, yaspin, xxhash, WebDataset, transformers, taming-transformers-rom1504, subprocess32, shortuuid, sentry-sdk, rotary-embedding-torch, pytorch-ranger, pathtools, GitPython, g-mlp-pytorch, ftfy, docker-pycreds, DALL-E, configparser, axial-positional-embedding, wandb, torch-optimizer, sentencepiece, nltk, datasets, dalle-pytorch, bitsandbytes-cuda111\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed DALL-E-0.1 GitPython-3.1.24 PyYAML-6.0 WebDataset-0.1.103 aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.8 async-timeout-4.0.1 asynctest-0.13.0 axial-positional-embedding-0.2.1 bitsandbytes-cuda111-0.26.0 blobfile-1.2.7 braceexpand-0.1.7 configparser-5.2.0 dalle-pytorch-1.1.2 datasets-1.16.1 docker-pycreds-0.4.0 einops-0.3.2 frozenlist-1.2.0 fsspec-2021.11.1 ftfy-6.0.3 future-0.18.2 g-mlp-pytorch-0.1.5 gitdb-4.0.9 huggingface-hub-0.2.1 multidict-5.2.0 mypy-0.910 mypy-extensions-0.4.3 nltk-3.6.5 omegaconf-2.1.1 pathtools-0.1.2 pyDeprecate-0.3.1 pycryptodomex-3.12.0 pytorch-lightning-1.5.5 pytorch-ranger-0.1.1 regex-2021.11.10 requests-2.26.0 rotary-embedding-torch-0.1.2 sacremoses-0.0.46 sentencepiece-0.1.96 sentry-sdk-1.5.0 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 taming-transformers-rom1504-0.0.6 tokenizers-0.10.3 torch-optimizer-0.3.0 torchmetrics-0.6.1 transformers-4.12.5 typed-ast-1.4.3 urllib3-1.26.7 wandb-0.12.7 xmltodict-0.12.0 xxhash-2.0.2 yarl-1.7.2 yaspin-2.1.0 youtokentome-1.0.6\n",
            "done!\n",
            "env: HF_ORGANIZATION_NAME=training-transformers-together\n",
            "env: HF_MODEL_NAME=dalle-v1\n",
            "env: WANDB_API_KEY=bfcfdc646d9481c372938d5370b4f902f7d7f420\n",
            "env: WANDB_ENTITY=learning-at-home\n",
            "env: WANDB_PROJECT=dalle-hivemind-trainers\n",
            "Dec 07 16:28:38.186 [\u001b[1m\u001b[34mINFO\u001b[0m] Trying 3 initial peers: ['/ip4/52.232.13.142/tcp/31234/p2p/QmWMNBvt3VkVETzQ68Uk44PokVjwA8sSvEEB3z8WwA5ZAS', '/ip4/193.106.95.184/tcp/31234/p2p/QmegUJSucRpaUrozQoP8B5ocAXhdnxQDrTdoUu5trtCoWc', '/ip4/52.232.13.143/tcp/31234/p2p/Qme6k7Ey6qz1sqi3QVzwXbop4UA33NP2sv6BStJqnvbRef']\n",
            "Dec 07 16:28:38.186 [\u001b[1m\u001b[34mINFO\u001b[0m] Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Downloading: 100% 773k/773k [00:00<00:00, 5.37MB/s]\n",
            "Downloading: 100% 1.32M/1.32M [00:00<00:00, 7.35MB/s]\n",
            "Downloading: 100% 1.17k/1.17k [00:00<00:00, 1.48MB/s]\n",
            "Dec 07 16:28:40.296 [\u001b[1m\u001b[34mINFO\u001b[0m] Checkpoint dir outputs, contents []\n",
            "Dec 07 16:28:40.297 [\u001b[1m\u001b[34mINFO\u001b[0m] Creating model\n",
            "Dec 07 16:28:42.118 [\u001b[1m\u001b[34mINFO\u001b[0m] Trainable parameters: 125894244\n",
            "Dec 07 16:28:58.621 [\u001b[1m\u001b[34mINFO\u001b[0m] Access for user justheuristic has been granted until 2021-12-07 22:28:58.596678 UTC\n",
            " You will contribute to the collaborative training under the username justheuristic\n",
            "Dec 07 16:29:01.336 [\u001b[1m\u001b[34mINFO\u001b[0m] Created client mode peer with peer_id=QmaLewDw2aotnTCNvbdULaVPb3nHhVyxrYKBSibEmb5vRA\n",
            "Dec 07 16:29:01.752 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3676 samples for epoch #82 from 9 peers. ETA 141.75 sec (refresh in 10.00 sec)\n",
            "Dec 07 16:29:02.854 [\u001b[1m\u001b[34mINFO\u001b[0m] Initializing optimizer manually since it has no tensors in state dict. To override this, provide initialize_optimizer=False\n",
            "Dec 07 16:29:12.776 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3698 samples for epoch #82 from 10 peers. ETA 135.42 sec (refresh in 10.00 sec)\n",
            "Downloading: 100% 2.14k/2.14k [00:00<00:00, 1.85MB/s]\n",
            "Dec 07 16:29:19.954 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1mdatasets.builder._create_builder_config:377\u001b[0m] Using custom data configuration default\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1054: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 100000000000000000000\n",
            "  Num Epochs = 9223372036854775807\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 100000000000000000000\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mttt-data\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "Dec 07 16:29:23.405 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3723 samples for epoch #82 from 10 peers. ETA 125.83 sec (refresh in 10.00 sec)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjustheuristic\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 猸锔 View project at \u001b[34m\u001b[4mhttps://wandb.ai/learning-at-home/dalle-hivemind-trainers\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/learning-at-home/dalle-hivemind-trainers/runs/2pxwu0ds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/dalle-hivemind/wandb/run-20211207_162920-2pxwu0ds\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Dec 07 16:29:25.126 [\u001b[1m\u001b[34mINFO\u001b[0m] Loading state from peers\n",
            "Dec 07 16:29:25.517 [\u001b[1m\u001b[34mINFO\u001b[0m] Downloading parameters from peer QmUsyqh996sGPvVCjeH8VWjjGdKWmMmo41pSZ9Q6AewBe3\n",
            "Dec 07 16:29:58.660 [\u001b[1m\u001b[34mINFO\u001b[0m] Finished downloading state from QmUsyqh996sGPvVCjeH8VWjjGdKWmMmo41pSZ9Q6AewBe3\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "Dec 07 16:30:02.561 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3831 samples for epoch #82 from 10 peers. ETA 92.89 sec (refresh in 10.00 sec)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:705: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  tensor = as_tensor(value)\n",
            "Dec 07 16:30:13.112 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3856 samples for epoch #82 from 10 peers. ETA 84.11 sec (refresh in 10.00 sec)\n",
            "Dec 07 16:30:23.668 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3886 samples for epoch #82 from 10 peers. ETA 71.80 sec (refresh in 10.00 sec)\n",
            "Dec 07 16:30:27.079 [\u001b[1m\u001b[34mINFO\u001b[0m] Current epoch: 82\n",
            "Dec 07 16:30:27.080 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 1 samples\n",
            "Dec 07 16:30:27.080 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 0.08092344140694996 samples/sec\n",
            "Dec 07 16:30:27.080 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 7.2902\n",
            "Dec 07 16:30:34.221 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3916 samples for epoch #82 from 10 peers. ETA 61.62 sec (refresh in 10.00 sec)\n",
            "Dec 07 16:30:44.784 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3939 samples for epoch #82 from 10 peers. ETA 51.43 sec (refresh in 10.00 sec)\n",
            "Dec 07 16:30:55.336 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 3993 samples for epoch #82 from 10 peers. ETA 33.06 sec (refresh in 10.00 sec)\n",
            "Dec 07 16:31:05.893 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 4019 samples for epoch #82 from 10 peers. ETA 21.98 sec (refresh in 10.00 sec)\n",
            "Dec 07 16:31:10.490 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 20.00 sec\n",
            "Dec 07 16:31:16.442 [\u001b[1m\u001b[34mINFO\u001b[0m] dalle-v1 accumulated 4048 samples for epoch #82 from 10 peers. ETA 11.58 sec (refresh in 8.91 sec)\n"
          ]
        }
      ]
    }
  ]
}